---
title: "FARE: Diagnostics for Fair Ranking using Pairwise Error Metrics."
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2009-10-01
venue: 'Journal 1'
paperurl: 'http://web.cs.wpi.edu/~cakuhlman/publications/fare.pdf'
citation: 'Caitlin Kuhlman, MaryAnn VanValkenburg, Elke Rundensteiner. (2019). "FARE: Diagnostics for Fair Ranking using Pairwise Error Metrics." <i>The Web Conference (WWW)</i>.'
---
Ranking, used extensively online and as a critical tool for decision making across many domains, may embed unfair bias against protected groups (as determined by sensitive data attributes, e.g., race, gender, or age). In this work we propose to broaden the scope of fairness assessment to include error-based fairness criteria for rankings, which heretofore has largely been limited to classification tasks. Our approach supports three criteria: Rank Equality, Rank Calibration, and Rank Parity, which cover a broad spectrum of fairness considerations from proportional group representation to error rate similarity. The underlying error metrics are formulated to be rank-appropriate, using pairwise discordance to measure prediction error in a modelagnostic fashion. Based on this foundation, we then design a fairness auditing mechanism which captures group differences throughout the entire ranking, generating in-depth, nuanced diagnostics. We demonstrate the efficacy of our error metrics using real-world scenarios, exposing trade-ofs among fairness criteria and providing guidance in the selection of fair-ranking algorithms

[Download paper here](http://web.cs.wpi.edu/~cakuhlman/publications/fare.pdf)

Recommended citation: Caitlin Kuhlman, MaryAnn VanValkenburg, Elke Rundensteiner. (2019). "FARE: Diagnostics for Fair Ranking using Pairwise Error Metrics." <i>The Web Conference (WWW)</i>.
